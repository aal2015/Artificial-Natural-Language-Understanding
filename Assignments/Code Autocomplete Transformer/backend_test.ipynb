{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593e3a6a-9746-4b4e-b824-f88f24f30a7c",
   "metadata": {},
   "source": [
    "# Test for Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de812202-72ef-4cb7-8007-e3a939bdf502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2a0a82-783b-478e-8dc1-c1923ed6e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a7092-b6af-4653-b1f7-1b376a9ec680",
   "metadata": {},
   "source": [
    "## Loading Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600088bc-af4b-428e-bafa-752b85db9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load('vocab_obj.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4ea37f-7382-428d-a6fb-f4dfd165ec46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 206, 73, 55]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['import', 'numpy', 'as', 'np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236cd5dc-4211-41d6-abbf-0154f598830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can reverse it....\n",
    "mapping = vocab.get_itos()\n",
    "\n",
    "#print 22, for example\n",
    "mapping[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e146cc9-fe78-4ee7-8000-a384238db21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try unknown vocab\n",
    "mapping[0]\n",
    "#they will all map to <unk> which has 0 as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4bc6e1-0bd7-4a57-b4a6-d06d0358c2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c90b27-c408-470f-9ff5-46597b4713eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11754"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731980ad-b261-4aba-a0fd-a9362c273c57",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c676db-d89d-459f-a8a3-14b36541fddc",
   "metadata": {},
   "source": [
    "#### Mutli Head Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9c51da-8e23-4fb5-8375-437df87191a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads  #make sure it's divisible....\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc   = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale   = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        b = q.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(q)\n",
    "        K = self.fc_k(k)\n",
    "        V = self.fc_v(v)\n",
    "        #Q, K, V = [b, l, h]\n",
    "        \n",
    "        #reshape them into head_dim\n",
    "        #reshape them to [b, n_heads, l, head_dim]\n",
    "        Q = Q.view(b, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(b, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(b, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        #Q, K, V = [b, n_heads, l, head_dim]\n",
    "        \n",
    "        #e = QK/sqrt(dk)\n",
    "        e = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        #e: [b, n_heads, ql, kl]\n",
    "        \n",
    "        if mask is not None:\n",
    "            e = e.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        a = torch.softmax(e, dim=-1)\n",
    "        \n",
    "        #eV\n",
    "        x = torch.matmul(self.dropout(a), V)\n",
    "        #x: [b, n_heads, ql, head_dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        #x: [b, ql, n_heads, head_dim]\n",
    "        \n",
    "        #concat them together\n",
    "        x = x.view(b, -1, self.hid_dim)\n",
    "        #x: [b, ql, h]\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        #x = [b, ql, h]\n",
    "        \n",
    "        return x, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12179470-1caf-4be8-94a0-58c0efdef3c1",
   "metadata": {},
   "source": [
    "#### Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5f40e9-29b4-4638-8a13-e2d7fa25f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(torch.relu(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2826c8-e096-4740-ac89-8e3fe2062ae5",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0476b039-2ccf-4a90-9460-c1dc80d8783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, \n",
    "                 pf_dim, dropout, trg_pad_idx, device, max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.trg_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        \n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim, \n",
    "                                                  dropout, \n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "        \n",
    "    def forward(self, trg):\n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "                \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)          \n",
    "        #pos = [batch size, trg len]\n",
    "            \n",
    "        trg = self.dropout((self.trg_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "                \n",
    "        for layer in self.layers:\n",
    "            trg = layer(trg, trg_mask)\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        #output = [batch size, trg len, output dim]\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41897ba8-36e6-41c1-ac08-9cc23b954151",
   "metadata": {},
   "source": [
    "#### Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d71a1b-08f2-4cd6-9d09-a8297f4781a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, trg_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        #self attention\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "            \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return trg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1a3ad-9200-47d9-9f94-ab3d3d07575d",
   "metadata": {},
   "source": [
    "#### Instance of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9060cc8-e3bc-4612-8139-499fb886a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = len(vocab)\n",
    "HID_DIM = 256\n",
    "DEC_LAYERS = 3\n",
    "DEC_HEADS = 8\n",
    "DEC_PF_DIM = 512\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "TRG_PAD_IDX = 1\n",
    "\n",
    "model = Decoder(OUTPUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, \n",
    "              DEC_PF_DIM, DEC_DROPOUT, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab17457-c08d-4a12-8536-3eaa510175cf",
   "metadata": {},
   "source": [
    "#### Loading Learned Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be5950fd-1f42-42a1-b452-3b0006cdefd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (trg_embedding): Embedding(11754, 256)\n",
       "  (pos_embedding): Embedding(100, 256)\n",
       "  (layers): ModuleList(\n",
       "    (0): DecoderLayer(\n",
       "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttentionLayer(\n",
       "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderLayer(\n",
       "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttentionLayer(\n",
       "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): DecoderLayer(\n",
       "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttentionLayer(\n",
       "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=256, out_features=11754, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = './models/Decoder.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45d4b3-461b-4be1-b11b-1bc63b3f3c7f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4571f838-d6c5-4d64-ac76-021eb38e2d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tokenize\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c669b9c4-1210-47da-86c8-fe0bed0aaaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_name = tokenize.tok_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf65397-5745-4fa0-b909-43ef68a58124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ENDMARKER', 1: 'NAME', 2: 'NUMBER', 3: 'STRING', 4: 'NEWLINE', 5: 'INDENT', 6: 'DEDENT', 7: 'LPAR', 8: 'RPAR', 9: 'LSQB', 10: 'RSQB', 11: 'COLON', 12: 'COMMA', 13: 'SEMI', 14: 'PLUS', 15: 'MINUS', 16: 'STAR', 17: 'SLASH', 18: 'VBAR', 19: 'AMPER', 20: 'LESS', 21: 'GREATER', 22: 'EQUAL', 23: 'DOT', 24: 'PERCENT', 25: 'LBRACE', 26: 'RBRACE', 27: 'EQEQUAL', 28: 'NOTEQUAL', 29: 'LESSEQUAL', 30: 'GREATEREQUAL', 31: 'TILDE', 32: 'CIRCUMFLEX', 33: 'LEFTSHIFT', 34: 'RIGHTSHIFT', 35: 'DOUBLESTAR', 36: 'PLUSEQUAL', 37: 'MINEQUAL', 38: 'STAREQUAL', 39: 'SLASHEQUAL', 40: 'PERCENTEQUAL', 41: 'AMPEREQUAL', 42: 'VBAREQUAL', 43: 'CIRCUMFLEXEQUAL', 44: 'LEFTSHIFTEQUAL', 45: 'RIGHTSHIFTEQUAL', 46: 'DOUBLESTAREQUAL', 47: 'DOUBLESLASH', 48: 'DOUBLESLASHEQUAL', 49: 'AT', 50: 'ATEQUAL', 51: 'RARROW', 52: 'ELLIPSIS', 53: 'COLONEQUAL', 54: 'OP', 55: 'AWAIT', 56: 'ASYNC', 57: 'TYPE_IGNORE', 58: 'TYPE_COMMENT', 59: 'ERRORTOKEN', 60: 'COMMENT', 61: 'NL', 62: 'ENCODING', 63: 'N_TOKENS', 256: 'NT_OFFSET'}\n"
     ]
    }
   ],
   "source": [
    "print(tok_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e88e700a-9616-4af1-a945-9d8983014949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_code_tokenizer(content):\n",
    "    tokenized_code = []\n",
    "    \n",
    "    try:\n",
    "        for token in tokenize.generate_tokens(io.StringIO(content).readline):\n",
    "            encoding = tok_name[token.type]\n",
    "            line = token.line\n",
    "            if line == '':\n",
    "                continue\n",
    "            \n",
    "            if encoding == \"COMMENT\" or encoding== \"NL\":\n",
    "                continue\n",
    "            elif encoding == \"NUMBER\":\n",
    "                tokenized_code.append(\"<NUMBER>\")\n",
    "            elif encoding == \"STRING\":\n",
    "                tokenized_code.append(\"<STRING>\")\n",
    "            else:\n",
    "                tokenized_code.append(token.string)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    return tokenized_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26291695-8b1e-4ec3-9d1c-578e03714ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_IDX, EOS_IDX = 2, 3\n",
    "\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = sequential_transforms(python_code_tokenizer, #Tokenization\n",
    "                                               vocab, #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35f11c36-ad93-4f7b-a217-f0d6bf612103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = \"import numpy as\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b577a8f0-5cc3-4d56-bfd5-7981b3b5d40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,  22, 206,  73,   3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = text_transform(sample).to(device)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fa28193-4b12-496b-ae9a-7f1d33ce3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = sample_text.reshape(1, -1)  #because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae56c64-9dff-407d-8b0d-4228fb316f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4596514-0b7b-4764-bf6c-ba8748e3b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([sample_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4c797cf-f06f-4e70-bec6-899065c822fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(sample_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cccc32d-c10a-4bb0-9383-83c45bfbeec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 11754])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7656544-e47d-410f-852c-7d0f7199bb65",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99e249b3-c5df-4587-892f-8cd28e10235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd436a5f-cf7a-4448-b6db-d3e7fdccf23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11754])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca08043-8947-4666-bae3-ae424e4a5649",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8ed8396-411d-417c-a3b1-117f100608f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 11754])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape #trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62294169-446a-4b2b-9dcd-d35f74766a4b",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "504c3590-28df-45ee-882a-7b15d7ccbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1) #returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5266ef3b-7449-4604-90a1-e958c4846cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  5, 12,  5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4d638a3-9c6c-4874-8d8b-1586689e6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f5bd53b-62fb-4f6c-8f0a-09754d6cf786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ":\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c9acdc7-6e17-4e21-8bea-cbaedb6c69bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  5, 12,  5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b474ceab-94da-41fb-aff3-5d9d3229dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<NUMBER>', '')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping[13], mapping[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5049df6-2045-442b-a500-f2a1d5426b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
